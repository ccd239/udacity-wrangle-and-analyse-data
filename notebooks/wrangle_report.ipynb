{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report: wrangle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This document was divided by the cleaning methodology steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Always to make a copy of each piece of data.**\n",
    "\n",
    "**2. Start with the completeness issues.**\n",
    "\n",
    "The first thing noticed is that none of the initial datasets contained the same number of values/rows (twitter_archive_enhanced:2356, image_predictions:2075, tweet_json:2028).\n",
    "  \n",
    "   Also, there were columns in the twitter_archive_enhanced some with missing values and others with \"None\" value which should be converted to missing value as well.\n",
    "   \n",
    "   On the other hand, some of these missing values are for irrelevant columns (the ones reffering to the replies and retweets) and other we cannot do anything (because these values are taken from text column. If this column does not contain the information we do not have anything else to have that info).\n",
    "\n",
    "**3. Address Tidiness After Structural Issues and Before Content Issues.**\n",
    "\n",
    "So the cleaning part started from the tidiness issues.\n",
    "\n",
    "The columns `doggo`, `floofer`, `pupper`, `puppo`, didn't look right, in the way that they all represent 1 variable:the dog stage. Also there were some rows (14) which contained 2 different dog stages. Those two issues break the first and second rules of tidiness. \n",
    "\n",
    "- The rows containing 2 different dog stages were adressed firstly, by separating them from the original dataset. The columns of all dog stages were concatenated so that we could have the multiple stages in 1 variable that I called 'dogstage'.\n",
    "\n",
    "- After that it was needed to adress the reviews that do not have dog stage associated; thus, created a new column `none_values` that turns \"None\" values for reviews with no dog stages associated (columns [`doggo`, `floofer`, `pupper`, `puppo`] =\"None\") and \"OK\" values for reviews with a dog stage associated.\n",
    "\n",
    "- Finally, the melt function was used in orther to create the new columns `dogstage` and `values`, and the rows were then quadrupled. For that reason at least 3 of the 4 rows generated for each initial row must be droped. Using \"ghost\" column `none_values`and the new columns `dogstage` and `value`, the rows without dog stages associated were dropped and the ones with \"None\" values were assumed as \"None\" values.\n",
    "\n",
    "- The columns `values`and `none_values` were dropped.\n",
    "\n",
    "Another tidiness issue was assessed: the 3 tables used in this assessment should be joined. This was addressed by changing the data type of image_predictions `tweet_id` to string followed by the pandas.merge function using a left join.\n",
    "\n",
    "**4. Cleaning the remaining data quality issues.**\n",
    "\n",
    "Regarding the remaining quality issues, the first thing done was to remove the tweets that represent retweets and replies to other tweets from the consolidated table. This was adressed filtering the dataset to remove the rows with values different than \"NaN\" in the `in_reply_to_status_id`and `retweeted_status_id`columns. Their `tweet_id`s were stored in a list. The `tweet_id`s were removed from image_predictions dataset using a query and the `tweet_id`s list.\n",
    "\n",
    "After removinging unwanted rows, the duplicated values were removed both for the twitter_archive_enhanced and the image_predictions datasets. This part is important because we make sure we are analysing always different reviews and predict different images. \n",
    "\n",
    "Visually looking to datasets can take us to notice data in more detail. Looking at the `name`column in the twitter_archive_enhanced dataset, it is possible to notice that some values do not correspond to actual dog names, and these values have a pattern: they all start with lower cases. Also, there is one that stands out because it occurs a lot of times: the \"a\" value. The values starting with lowercases were replaced by \"None\", because there are many for which we do not have that information really. And 2 were picked up to be corrected: \"O´Malley\" instead of \"O\" and \"Quizno\" instead of \"his\".\n",
    "\n",
    "Final steps were to correct null values represented as \"None\" and change the data types of the variables `timestamp`and `dog_stage`to datetype and categorical respectively.\n",
    "\n",
    "Some of the issues pointed out in the Assessment part are not the same as these described because while cleaning the original datasets, some columns were dropped or melted and also for cleaning some issues others were also addressed (for example, changing the data type of the `tweet_id`to str in the image_predictions table, before cleaning the non-wanted values).\n",
    "\n",
    "There are several entries in ´names´ column with strange characters like: Ralph├®, Olivi├®r (2 times), Am├®lie, G├▓rd├│n, for which it was decided to keep as is, once there is no clue in the remaining data on how to clean these values.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
