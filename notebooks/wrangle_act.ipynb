{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Project: Wrangling and Analyze Data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Project: Wrangling and Analyze Data](#toc1_)    \n",
    "  - [Data Gathering](#toc1_1_)    \n",
    "    - [Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)](#toc1_1_1_)    \n",
    "    - [Use the Requests library to download the tweet image prediction (image_predictions.tsv)](#toc1_1_2_)    \n",
    "    - [Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)](#toc1_1_3_)    \n",
    "  - [Assessing Data](#toc1_2_)    \n",
    "    - [Quality issues](#toc1_2_1_)    \n",
    "    - [Tidiness issues](#toc1_2_2_)    \n",
    "  - [Cleaning Data](#toc1_3_)    \n",
    "    - [Issue #1:](#toc1_3_1_)    \n",
    "      - [Define:](#toc1_3_1_1_)    \n",
    "      - [Code](#toc1_3_1_2_)    \n",
    "      - [Test](#toc1_3_1_3_)    \n",
    "    - [Issue #2:](#toc1_3_2_)    \n",
    "      - [Define](#toc1_3_2_1_)    \n",
    "      - [Code](#toc1_3_2_2_)    \n",
    "      - [Test](#toc1_3_2_3_)    \n",
    "  - [Storing Data](#toc1_4_)    \n",
    "  - [Analyzing and Visualizing Data](#toc1_5_)    \n",
    "    - [Insights:](#toc1_5_1_)    \n",
    "    - [Visualization](#toc1_5_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Data Gathering](#toc0_)\n",
    "In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the libraries necessary in this workbook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"../data/twitter-archive-enhanced.csv\", sep= \",\",)\n",
    "df1.head(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change tweet_id from int to str\n",
    "df1['tweet_id']=df1['tweet_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of member ids contained in this dataset\n",
    "tweet_id_list= df1.tweet_id.tolist()\n",
    "print(tweet_id_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Use the Requests library to download the tweet image prediction (image_predictions.tsv)](#toc0_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Use the requests library to programmatically download a file\n",
    "\n",
    "#Create the request\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "\n",
    "#Access the content and write to a file\n",
    "if not os.path.isfile('../data/image_predictions.tsv'): #making sure it only downloads if file does not exist yet\n",
    "    with open('../data/image_predictions.tsv', 'wb') as f: \n",
    "        f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file downloaded\n",
    "df2 = pd.read_csv(\"../data/image_predictions.tsv\", sep='\\t')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting started on the Twitter API\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "import credentials\n",
    "\n",
    "auth = OAuthHandler(credentials.consumer_key, credentials.consumer_secret)\n",
    "auth.set_access_token(credentials.access_token, credentials.access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_id_list:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except Exception as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Tue Aug 01 16:23:56 +0000 2017',\n",
       " 'id': 892420643555336193,\n",
       " 'id_str': '892420643555336193',\n",
       " 'full_text': \"This is Phineas. He's a mystical boy. Only ever appears in the hole of a donut. 13/10 https://t.co/MgUWQ76dJU\",\n",
       " 'truncated': False,\n",
       " 'display_text_range': [0, 85],\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [],\n",
       "  'urls': [],\n",
       "  'media': [{'id': 892420639486877696,\n",
       "    'id_str': '892420639486877696',\n",
       "    'indices': [86, 109],\n",
       "    'media_url': 'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\n",
       "    'url': 'https://t.co/MgUWQ76dJU',\n",
       "    'display_url': 'pic.twitter.com/MgUWQ76dJU',\n",
       "    'expanded_url': 'https://twitter.com/dog_rates/status/892420643555336193/photo/1',\n",
       "    'type': 'photo',\n",
       "    'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "     'medium': {'w': 540, 'h': 528, 'resize': 'fit'},\n",
       "     'small': {'w': 540, 'h': 528, 'resize': 'fit'},\n",
       "     'large': {'w': 540, 'h': 528, 'resize': 'fit'}}}]},\n",
       " 'extended_entities': {'media': [{'id': 892420639486877696,\n",
       "    'id_str': '892420639486877696',\n",
       "    'indices': [86, 109],\n",
       "    'media_url': 'http://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg',\n",
       "    'url': 'https://t.co/MgUWQ76dJU',\n",
       "    'display_url': 'pic.twitter.com/MgUWQ76dJU',\n",
       "    'expanded_url': 'https://twitter.com/dog_rates/status/892420643555336193/photo/1',\n",
       "    'type': 'photo',\n",
       "    'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "     'medium': {'w': 540, 'h': 528, 'resize': 'fit'},\n",
       "     'small': {'w': 540, 'h': 528, 'resize': 'fit'},\n",
       "     'large': {'w': 540, 'h': 528, 'resize': 'fit'}}}]},\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 4196983835,\n",
       "  'id_str': '4196983835',\n",
       "  'name': 'WeRateDogs®',\n",
       "  'screen_name': 'dog_rates',\n",
       "  'location': 'all our links ➜',\n",
       "  'description': 'Your Only Source For Professional Dog Ratings Instagram and Facebook ➜ WeRateDogs partnerships@weratedogs.com | nonprofit: @15outof10 ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀',\n",
       "  'url': 'https://t.co/YPc2Xq4Va2',\n",
       "  'entities': {'url': {'urls': [{'url': 'https://t.co/YPc2Xq4Va2',\n",
       "      'expanded_url': 'http://links.weratedogs.com',\n",
       "      'display_url': 'links.weratedogs.com',\n",
       "      'indices': [0, 23]}]},\n",
       "   'description': {'urls': []}},\n",
       "  'protected': False,\n",
       "  'followers_count': 9379952,\n",
       "  'friends_count': 21,\n",
       "  'listed_count': 7677,\n",
       "  'created_at': 'Sun Nov 15 21:41:29 +0000 2015',\n",
       "  'favourites_count': 148427,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'verified': True,\n",
       "  'statuses_count': 16507,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': False,\n",
       "  'profile_background_color': '000000',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1576252749800386560/fhEuI2BO_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1576252749800386560/fhEuI2BO_normal.jpg',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/4196983835/1661991479',\n",
       "  'profile_link_color': 'F5ABB5',\n",
       "  'profile_sidebar_border_color': '000000',\n",
       "  'profile_sidebar_fill_color': '000000',\n",
       "  'profile_text_color': '000000',\n",
       "  'profile_use_background_image': False,\n",
       "  'has_extended_profile': False,\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': False,\n",
       "  'follow_request_sent': False,\n",
       "  'notifications': False,\n",
       "  'translator_type': 'none',\n",
       "  'withheld_in_countries': []},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 6953,\n",
       " 'favorite_count': 33626,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'possibly_sensitive_appealable': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading json data from the saved txt file\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "df_list=[]\n",
    "\n",
    "path = 'C:\\\\Users\\\\catar\\\\data-projects\\\\Github\\\\udacity-wrangle-and-analyse-data\\\\data\\\\tweet_json.txt'\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        df_list.append(json.loads(line))\n",
    "\n",
    "#Printing the first line of the text file        \n",
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contributors',\n",
       " 'coordinates',\n",
       " 'created_at',\n",
       " 'display_text_range',\n",
       " 'entities',\n",
       " 'extended_entities',\n",
       " 'favorite_count',\n",
       " 'favorited',\n",
       " 'full_text',\n",
       " 'geo',\n",
       " 'id',\n",
       " 'id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'in_reply_to_status_id',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'is_quote_status',\n",
       " 'lang',\n",
       " 'place',\n",
       " 'possibly_sensitive',\n",
       " 'possibly_sensitive_appealable',\n",
       " 'retweet_count',\n",
       " 'retweeted',\n",
       " 'source',\n",
       " 'truncated',\n",
       " 'user']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the list of the first line keys (which should be the same for all the lines)\n",
    "sorted(df_list[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe from list of dictionaires\n",
    "df3=pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>33626</td>\n",
       "      <td>6953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>29162</td>\n",
       "      <td>5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>21940</td>\n",
       "      <td>3462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>36701</td>\n",
       "      <td>7171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>35098</td>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>671485057807351808</td>\n",
       "      <td>673</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>671390180817915904</td>\n",
       "      <td>1274</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>671362598324076544</td>\n",
       "      <td>974</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>671357843010908160</td>\n",
       "      <td>351</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>671355857343524864</td>\n",
       "      <td>419</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2028 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id_str  favorite_count  retweet_count\n",
       "0     892420643555336193           33626           6953\n",
       "1     892177421306343426           29162           5255\n",
       "2     891815181378084864           21940           3462\n",
       "3     891689557279858688           36701           7171\n",
       "4     891327558926688256           35098           7700\n",
       "...                  ...             ...            ...\n",
       "2023  671485057807351808             673            195\n",
       "2024  671390180817915904            1274            647\n",
       "2025  671362598324076544             974            257\n",
       "2026  671357843010908160             351            133\n",
       "2027  671355857343524864             419            104\n",
       "\n",
       "[2028 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only the columns we want to extract and store it in a dataframe (dt_3)\n",
    "df3=df3[['id_str','favorite_count','retweet_count']]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> [!IMPORTANT] After gathering saving the data in files I changed some code cells to markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Assessing Data](#toc0_)\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n",
    "programmatic assessement to assess the data.\n",
    "\n",
    "**Note:** pay attention to the following key points when you access the data.\n",
    "\n",
    "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This [unique rating system](http://knowyourmeme.com/memes/theyre-good-dogs-brent) is a big part of the popularity of WeRateDogs.\n",
    "* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Quality issues](#toc0_)\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3.\n",
    "\n",
    "4.\n",
    "\n",
    "5.\n",
    "\n",
    "6.\n",
    "\n",
    "7.\n",
    "\n",
    "8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[Tidiness issues](#toc0_)\n",
    "1.\n",
    "\n",
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Cleaning Data](#toc0_)\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Issue #1:](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_1_1_'></a>[Define:](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_1_2_'></a>[Code](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_1_3_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Issue #2:](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_1_'></a>[Define](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_2_'></a>[Code](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_3_'></a>[Test](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Storing Data](#toc0_)\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Analyzing and Visualizing Data](#toc0_)\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_1_'></a>[Insights:](#toc0_)\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_2_'></a>[Visualization](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
